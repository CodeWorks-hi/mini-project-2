import streamlit as st
import re
import requests
from huggingface_hub import InferenceClient
from bs4 import BeautifulSoup

TEXT_MODEL_ID = "google/gemma-2-9b-it"

def fetch_latest_news(keyword="í˜„ëŒ€ìë™ì°¨", count=5):
    try:
        search_url = f"https://search.naver.com/search.naver?where=news&query={keyword}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(search_url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        news_items = []
        news_elements = soup.select('.news_area')
        
        for i, item in enumerate(news_elements):
            if i >= count:
                break
                
            title_element = item.select_one('.news_tit')
            title = title_element.text if title_element else "ì œëª© ì—†ìŒ"
            link = title_element['href'] if title_element else ""
            
            summary_element = item.select_one('.dsc_wrap')
            summary = summary_element.text.strip() if summary_element else "ìš”ì•½ ì—†ìŒ"
            
            date_element = item.select_one('.info_group span.info')
            date = date_element.text if date_element else "ë‚ ì§œ ì—†ìŒ"
            
            news_items.append({
                'title': title,
                'link': link,
                'description': summary,
                'pubDate': date
            })
        
        st.session_state.latest_news = news_items
        return news_items
        
    except Exception as e:
        st.error(f"ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return []

def get_huggingface_token(model_type):
    tokens = {"gemma": st.secrets.get("HUGGINGFACE_API_TOKEN_GEMMA")}
    return tokens.get(model_type)

def clean_input(text: str) -> str:
    return re.sub(r"(í•´ì¤˜|ì•Œë ¤ì¤˜|ì„¤ëª…í•´ ì¤˜|ë§í•´ ì¤˜)", "", text).strip()

def clean_html_tags(text):
    return re.sub(r'<[^>]+>', '', text)

def remove_unwanted_phrases(text: str) -> str:
    """
    ìƒì„±ëœ ê²°ê³¼ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ë¬¸êµ¬(ì˜ˆ: '[ê¸°íƒ€]', 'ìœ„ ë‚´ìš©ì€ ì§ˆë¬¸ì— ëŒ€í•œ', 
    'ë³´ê³ ì„œ ì‘ì„±ì„ ìœ„í•´ í•„ìš”í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ì§€ìš”?' ë“±)ë¥¼ í¬í•¨í•œ ì¤„ì„ ì œê±°
    """
    lines = text.splitlines()
    filtered_lines = []
    for line in lines:
        if "[ê¸°íƒ€]" in line:
            continue
        if "ìœ„ ë‚´ìš©ì€ ì§ˆë¬¸ì— ëŒ€í•œ" in line:
            continue
        # ì¶”ê°€: ë³´ê³ ì„œ ì‘ì„±ì„ ìœ„í•œ ë¬¸êµ¬ ì œê±°
        if "ë³´ê³ ì„œ ì‘ì„±ì„ ìœ„í•´ í•„ìš”í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ì§€ìš”?" in line:
            continue
        
        filtered_lines.append(line)
    
    return "\n".join(filtered_lines)

def format_news_for_prompt(news_items):
    if not news_items:
        return "ìµœì‹  ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_news = "## ìµœì‹  ìë™ì°¨ ì‚°ì—… ë‰´ìŠ¤\n\n"
    for i, item in enumerate(news_items[:5], 1):
        formatted_news += f"{i}. {item['title']} ({item['pubDate']})\n"
        formatted_news += f"   ìš”ì•½: {item['description'][:100]}...\n\n"
    
    return formatted_news

def format_predictions_for_api(predictions):
    if not predictions:
        return {}
        
    pred_type = predictions.get('type', '')
    
    if pred_type == 'region':
        region_name = predictions.get('name', 'ì§€ì—­ ì •ë³´ ì—†ìŒ')
        forecast = predictions.get('forecast', {})
        
        result = f"## {region_name} ì§€ì—­ ìˆ˜ì¶œëŸ‰ ì˜ˆì¸¡\n\n"
        result += "| ì—°ë„ | ì›” | ì˜ˆì¸¡ ìˆ˜ì¶œëŸ‰ |\n|-----|-----|-----|\n"
        
        years = forecast.get('ì—°ë„', {})
        months = forecast.get('ì›”', {})
        exports = forecast.get('ì˜ˆì¸¡ ìˆ˜ì¶œëŸ‰', {})
        
        if years and months and exports:
            for i in range(len(years)):
                result += f"| {years.get(str(i), '')} | {months.get(str(i), '')} | {exports.get(str(i), '')} |\n"
        
        return result
    
    elif pred_type == 'car':
        car_name = predictions.get('name', 'ì°¨ì¢… ì •ë³´ ì—†ìŒ')
        forecast = predictions.get('forecast', {})
        
        result = f"## {car_name} ì°¨ì¢… íŒë§¤ëŸ‰ ì˜ˆì¸¡\n\n"
        result += "| ì—°ë„ | ì›” | ì˜ˆì¸¡ íŒë§¤ëŸ‰ |\n|-----|-----|-----|\n"
        
        years = forecast.get('ì—°ë„', {})
        months = forecast.get('ì›”', {})
        sales = forecast.get('ì˜ˆì¸¡ íŒë§¤ëŸ‰', {})
        
        if years and months and sales:
            for i in range(len(years)):
                result += f"| {years.get(str(i), '')} | {months.get(str(i), '')} | {sales.get(str(i), '')} |\n"
        
        return result
    
    elif pred_type == 'plant':
        plant_name = predictions.get('name', 'ê³µì¥ ì •ë³´ ì—†ìŒ')
        forecast = predictions.get('forecast', {})
        
        result = f"## {plant_name} ê³µì¥ ìƒì‚°ëŸ‰ ì˜ˆì¸¡\n\n"
        result += "| ì—°ë„ | ì›” | ì˜ˆì¸¡ ìƒì‚°ëŸ‰ |\n|-----|-----|-----|\n"
        
        years = forecast.get('ì—°ë„', {})
        months = forecast.get('ì›”', {})
        production = forecast.get('ì˜ˆì¸¡ íŒë§¤ëŸ‰', {})
        
        if years and months and production:
            for i in range(len(years)):
                result += f"| {years.get(str(i), '')} | {months.get(str(i), '')} | {production.get(str(i), '')} |\n"
        
        return result
    
    return str(predictions)

def generate_text_via_api(prompt: str, predictions: dict, news_items: list, model_name: str = TEXT_MODEL_ID) -> str:
    token = get_huggingface_token("gemma")
    if not token:
        st.error("Hugging Face API í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return ""

    predictions_formatted = format_predictions_for_api(predictions)
    news_text = format_news_for_prompt(news_items)
    
    system_prompt = """
    [ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­]
    ### 1. ë¶„ì„ ìš”êµ¬ì‚¬í•­
    - í˜„ëŒ€/ê¸°ì•„ ê¸€ë¡œë²Œ íŒë§¤ ì „ëµ ë¶„ì„
    - ì˜ˆì¸¡ ë°ì´í„°ì™€ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•œ ë¶„ì„
    - ì§€ì—­ë³„(ë¶ë¯¸, ìœ ëŸ½, ì•„ì‹œì•„) íŒë§¤ ì „ëµ êµ¬ë¶„ ì„¤ëª…
    - í™˜ìœ¨ ë³€ë™ì´ ìˆ˜ì¶œ ì „ëµì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
    - ê²½ì œ ìƒí™©ì— ë”°ë¥¸ ê¸ì •ì /ë¶€ì •ì  ìš”ì¸ êµ¬ë¶„
    - 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤(ë‚™ê´€/ì¤‘ë¦½/ë¹„ê´€)ë¡œ íŒë§¤ëŸ‰ ì˜ˆì¸¡

    ### 2. ì¶œë ¥ í˜•ì‹
    ## 2025 í˜„ëŒ€/ê¸°ì•„ ê¸€ë¡œë²Œ ì‹œì¥ ì „ë§ ë³´ê³ ì„œ
    | êµ¬ë¶„ | 2024 | 2025ì˜ˆìƒ | ì¦ê°ë¥  |
    |------|------|----------|--------|
    | ê¸€ë¡œë²Œ íŒë§¤ëŸ‰ | Xë§Œ ëŒ€ | Yë§Œ ëŒ€ | Z% |
    | ì£¼ìš” ì‹œì¥ ì ìœ ìœ¨ | A% | B% | C%p |

    - ì£¼ìš” ì „ëµ:
    - ë¦¬ìŠ¤í¬ ìš”ì¸:
    """

    full_prompt = f"{system_prompt}\n\n[ì˜ˆì¸¡ ë°ì´í„°]\n{predictions_formatted}\n\n[ìµœì‹  ë‰´ìŠ¤]\n{news_text}\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{prompt}"
    
    try:
        client = InferenceClient(model=model_name, token=token)
        response = client.text_generation(
            prompt=f"ë‹¤ìŒ ìš”ì²­ì— ë§ëŠ” ë¶„ì„ì„ ì „ë¬¸ê°€ì²˜ëŸ¼ 1000ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì¤˜:\n{full_prompt}",
            max_new_tokens=1000,
            temperature=0.7
        )
        return response
    except Exception as e:
        st.error(f"í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return ""


def recommendations_ui():
    st.title("AI ê¸°ë°˜ ì‹œì¥ ì˜ˆì¸¡ ë° ë¶„ì„")
    st.markdown("""
    - ì˜ˆì¸¡ ë°ì´í„°ì™€ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì¢…í•©í•œ ì‹¬ì¸µ ë¶„ì„ ì œê³µ
    - ìµœì‹  AI ê¸°ìˆ ì„ í™œìš©í•œ ì‹œì¥ ë™í–¥ ì˜ˆì¸¡
    - ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ê²°ê³¼ ë„ì¶œ
    """)

    if 'predictions' not in st.session_state:
        st.warning("ë¨¼ì € 'ì˜ˆì¸¡ ì‹œìŠ¤í…œ' íƒ­ì—ì„œ ì˜ˆì¸¡ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    with st.expander("ì˜ˆì¸¡ ê²°ê³¼ í‘œ (LSTM ê¸°ë°˜)"):
        st.write(st.session_state.predictions)
        formatted_predictions = format_predictions_for_api(st.session_state.predictions)
        st.markdown("### í˜•ì‹ ë³€í™˜ëœ ì˜ˆì¸¡ ë°ì´í„°")
        st.markdown(formatted_predictions)

    # ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ê°€ì ¸ì˜¤ê¸°
    if 'latest_news' not in st.session_state:
        with st.spinner("ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            news_items = fetch_latest_news()
            if news_items:
                st.session_state.latest_news = news_items
            else:
                st.error("ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return

    # ì²« ë²ˆì§¸ í¼ (í‚¤: analyze_form)
    with st.form("analyze_form"):
        user_input = st.text_area("ì˜ˆì¸¡ ë° ë¶„ì„ ì…ë ¥", placeholder="ì˜ˆ: 2025ë…„ ë¯¸êµ­ ìˆ˜ì¶œ ì˜ˆì¸¡í•´ì¤˜")
        submitted = st.form_submit_button("ì˜ˆì¸¡ ë° ë¶„ì„ ì‹¤í–‰")
    
    if submitted:
        with st.spinner("ì‹œì¥ ì˜ˆì¸¡ ë° ë¶„ì„ ì¤‘..."):
            cleaned = clean_input(user_input)
            raw_result_txt = generate_text_via_api(cleaned, st.session_state.predictions, st.session_state.latest_news)
            
            # í›„ì²˜ë¦¬: ì›ì¹˜ ì•ŠëŠ” ë¬¸êµ¬ ì œê±°
            final_result_txt = remove_unwanted_phrases(raw_result_txt)
            
            st.session_state.analysis_result = final_result_txt
            st.markdown(f"### ì¢…í•© ì˜ˆì¸¡ ë° ë¶„ì„ ê²°ê³¼\n{final_result_txt}")

    # ìµœì‹  ë‰´ìŠ¤ í‘œì‹œ
    with st.expander("ğŸ“° ë¶„ì„ì— ì‚¬ìš©ëœ ìµœì‹  ë‰´ìŠ¤"):
        for i, news in enumerate(st.session_state.latest_news[:5], 1):
            title = clean_html_tags(news['title'])
            description = clean_html_tags(news['description'])
            
            st.markdown(
                f"""
                <div style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 15px; border-left: 4px solid #4285f4;">
                    <h4 style="margin-top: 0; color: #333;">{i}. {title}</h4>
                    <p style="color: #555;">{description[:150]}...</p>
                    <p style="color: #888; font-size: 0.8em;">{news.get('pubDate', '')}</p>
                </div>
                """, 
                unsafe_allow_html=True
            )

    # ---- ì¤‘ë³µ í¼ ì œê±° ë˜ëŠ” í‚¤ ë³€ê²½ ----
    #
    # ì•„ë˜ì™€ ê°™ì€ ë‘ ë²ˆì§¸ í¼ì´ ì¤‘ë³µë˜ì–´ ìˆë‹¤ë©´, í‚¤ë¥¼ "analyze_form2"ì²˜ëŸ¼ ë°”ê¾¸ê±°ë‚˜
    # í¼ì´ ì‹¤ì œë¡œ í•„ìš” ì—†ë‹¤ë©´ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.
    #
    # [ì˜ˆì‹œ] í‚¤ë¥¼ ë³€ê²½í•œ í¼
    #
    # with st.form("analyze_form2"):
    #     user_input2 = st.text_area("ì¶”ê°€ ë¶„ì„ ì…ë ¥", placeholder="ì˜ˆ: ì¤‘ë™ ì‹œì¥ ì§„ì¶œ ì „ëµ ì•Œë ¤ì¤˜")
    #     submitted2 = st.form_submit_button("ì¶”ê°€ ë¶„ì„ ì‹¤í–‰")
    # 
    # if submitted2:
    #     with st.spinner("ì¶”ê°€ ë¶„ì„ ì¤‘..."):
    #         cleaned2 = clean_input(user_input2)
    #         result_txt2 = generate_text_via_api(cleaned2, st.session_state.predictions, st.session_state.latest_news)
    #         st.markdown(f"### ì¶”ê°€ ë¶„ì„ ê²°ê³¼\n{result_txt2}")
