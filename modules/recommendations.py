import streamlit as st
import re
import requests
import torch
from PIL import Image
from io import BytesIO
from transformers import AutoProcessor, LlavaForConditionalGeneration
from huggingface_hub import InferenceClient

# =====================
# ì„¤ì •
# =====================
VISION_MODEL_ID = "llava-hf/llava-1.5-7b-hf"
TEXT_MODEL_ID = "google/gemma-2-9b-it"
MAX_IMAGE_SIZE = 2048

# =====================
# í† í° ë¡œë”©
# =====================
def get_huggingface_tokens():
    return {
        "llava": st.secrets.get("HUGGINGFACE_API_TOKEN_LLAVA"),
        "gemma": st.secrets.get("HUGGINGFACE_API_TOKEN_GEMMA")
    }

def get_huggingface_token(model_type):
    return get_huggingface_tokens().get(model_type)

# =====================
# ì…ë ¥ ì •ì œ
# =====================
def clean_input(text: str) -> str:
    return re.sub(r"\b(í•´ì¤˜|ì•Œë ¤ì¤˜|ì„¤ëª…í•´ ì¤˜|ë§í•´ ì¤˜)\b", "", text, flags=re.IGNORECASE).strip()

# =====================
# í…ìŠ¤íŠ¸ ìƒì„± (Gemma API)
# =====================
def generate_text_via_api(prompt: str, model_name: str = TEXT_MODEL_ID) -> str:
    token = get_huggingface_token("gemma")
    if not token:
        st.error("âŒ Hugging Face API í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return ""

    prompt_additions = [
        "í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ì‘ì„±í•´ì¤˜",
        "ì‹œì¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ í¬í•¨í•´ì¤˜",
        "ê¸ì •ì /ë¶€ì •ì  ìš”ì¸ì„ ë‚˜ëˆ ì„œ ì •ë¦¬í•´ì¤˜",
        "3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤(ë‚™ê´€/ì¤‘ë¦½/ë¹„ê´€)ë¡œ ì˜ˆì¸¡í•´ì¤˜",
        "ê°„ê²°í•˜ê²Œ í•µì‹¬ ìœ„ì£¼ë¡œ ìš”ì•½í•´ì¤˜ (500ì ì´ë‚´)"
    ]

    enhanced_prompt = f"{prompt}\n\nì¶”ê°€ ì§€ì‹œì‚¬í•­:\n" + "\n".join(prompt_additions)

    try:
        client = InferenceClient(model=model_name, token=token)
        response = client.text_generation(
            prompt=f"ì „ë¬¸ê°€ì²˜ëŸ¼ ë‹¤ìŒ ìš”ì²­ì— ëŒ€í•´ ë¶„ì„í•´ì¤˜:\n{enhanced_prompt}",
            max_new_tokens=512,
            temperature=0.7
        )
        return response
    except Exception as e:
        st.error(f"API ì˜¤ë¥˜: {e}")
        return ""

# =====================
# ì´ë¯¸ì§€ ë¶„ì„ (LLaVA ë¡œì»¬ ì‹¤í–‰)
# =====================
def analyze_image_with_llava(image: Image.Image, question: str) -> str:
    processor = AutoProcessor.from_pretrained(VISION_MODEL_ID)
    model = LlavaForConditionalGeneration.from_pretrained(
        VISION_MODEL_ID,
        torch_dtype=torch.bfloat16,
        device_map="auto"
    )

    messages = [{
        "role": "user",
        "content": [
            {"type": "image", "image": image},
            {"type": "text", "text": question}
        ],
    }]

    inputs = processor(
        text=processor.apply_chat_template(messages, add_generation_prompt=True),
        images=image,
        return_tensors="pt"
    ).to(model.device, torch.bfloat16)

    output = model.generate(
        **inputs,
        max_new_tokens=256,
        temperature=0.3,
        top_p=0.95,
        do_sample=True,
        repetition_penalty=1.2,
        use_cache=True
    )

    result = processor.decode(
        output[0],
        skip_special_tokens=True,
        clean_up_tokenization_spaces=True
    )
    return result

# =====================
# Streamlit UI
# =====================
def recommendations_ui():
    st.title("ğŸ¤– AI ìˆ˜ì¶œ ë¶„ì„ & ì°¨ëŸ‰ ì¶”ì²œ ì‹œìŠ¤í…œ")
    st.info("ì°¨ëŸ‰ ì´ë¯¸ì§€ë‚˜ ì§ˆë¬¸ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ê³¼ ì˜ˆì¸¡ì„ ì œê³µí•©ë‹ˆë‹¤.")

    with st.form("recommend_form"):
        image_file = st.file_uploader("ğŸ“· ì°¨ëŸ‰ ë˜ëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì„ íƒ)", type=["jpg", "png"])
        user_input = st.text_area(
            "ğŸ“ ë¶„ì„ ì§ˆë¬¸ ì…ë ¥",
            placeholder="ì˜ˆ: ë¶ë¯¸ ì‹œì¥ì—ì„œ ì´ ì „ê¸° SUVì˜ ìˆ˜ìš” ì˜ˆì¸¡",
            height=120
        )
        submitted = st.form_submit_button("ğŸš€ ë¶„ì„ ì‹¤í–‰")

    if submitted:
        results = []

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        if image_file:
            try:
                image = Image.open(image_file).convert("RGB")
                st.image(image, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", use_column_width=True)
                with st.spinner("ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                    result_img = analyze_image_with_llava(image, user_input or "ì´ ì°¨ëŸ‰ì˜ íŠ¹ì§•ê³¼ ì‹œì¥ ë¶„ì„ì„ í•´ì¤˜")
                    results.append(f"### ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼\n{result_img}")
            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        # í…ìŠ¤íŠ¸ ë¶„ì„
        if user_input:
            with st.spinner("ğŸ“Š í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ ìƒì„± ì¤‘..."):
                cleaned = clean_input(user_input)
                result_text = generate_text_via_api(cleaned)
                results.append(f"### ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼\n{result_text}")

        # ê²°ê³¼ ì¶œë ¥
        if results:
            st.divider()
            for r in results:
                st.markdown(r)
        else:
            st.warning("ì…ë ¥ ë‚´ìš© ë˜ëŠ” ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
