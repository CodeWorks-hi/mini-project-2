import streamlit as st
import pandas as pd
import pydeck as pdk
import requests
import re
import altair as alt

############################
# 1) CSV íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
############################
@st.cache_data
def load_csv(file_path):
    try:
        df = pd.read_csv(file_path)
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e}")
        return None

############################
# 2) HTML íƒœê·¸ ì œê±° í•¨ìˆ˜
############################
def remove_html_tags(text: str) -> str:
    return re.sub(r"<.*?>", "", text)

############################
# 3) ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ í•¨ìˆ˜
############################
def fetch_naver_news(query: str, display: int = 3, sort: str = "date"):
    try:
        client_id = st.secrets["naver"]["client_id"]
        client_secret = st.secrets["naver"]["client_secret"]
    except Exception as e:
        st.error("ë„¤ì´ë²„ API í‚¤ê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. secrets.tomlì„ í™•ì¸í•˜ì„¸ìš”.")
        return []

    url = "https://openapi.naver.com/v1/search/news.json"
    params = {"query": query, "display": display, "sort": sort}
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret
    }

    response = requests.get(url, params=params, headers=headers)
    if response.status_code == 200:
        return response.json().get("items", [])
    else:
        st.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨ (status code: {response.status_code})")
        return []

############################
# 4) ë©”ì¸ ëŒ€ì‹œë³´ë“œ í•¨ìˆ˜
############################
def dashboard_ui():
    # --------------------------
    # ë°ì´í„° ë¡œë“œ (í˜„ëŒ€ì™€ ê¸°ì•„)
    # --------------------------
    df_h = load_csv("data/processed/í˜„ëŒ€_ì§€ì—­ë³„ìˆ˜ì¶œì‹¤ì _ì „ì²˜ë¦¬.CSV")
    df_k = load_csv("data/processed/ê¸°ì•„_ì§€ì—­ë³„ìˆ˜ì¶œì‹¤ì _ì „ì²˜ë¦¬.CSV")
    if df_h is None or df_k is None:
        st.stop()
    
    df_h["ë¸Œëœë“œ"] = "í˜„ëŒ€"
    df_k["ë¸Œëœë“œ"] = "ê¸°ì•„"

    # ğŸš¨ í˜„ëŒ€ì—ëŠ” ì°¨ëŸ‰ êµ¬ë¶„ì´ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì¶”ê°€
    if "ì°¨ëŸ‰ êµ¬ë¶„" not in df_h.columns:
        df_h["ì°¨ëŸ‰ êµ¬ë¶„"] = "ê¸°íƒ€"

    # ë³‘í•©
    df = pd.concat([df_h, df_k], ignore_index=True)

    # ì›”ë³„ ì»¬ëŸ¼ ìˆ«ìí˜• ë³€í™˜
    month_cols = [f"{i}ì›”" for i in range(1, 13)]
    for col in month_cols:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    # --------------------------
    # ì°¨ëŸ‰ êµ¬ë¶„ë³„ ìƒ‰ìƒ ì •ì˜
    # --------------------------
    color_map = {
        "Passenger Car": [152, 251, 152, 160],
        "Recreational Vehicle": [255, 165, 0, 160],
        "Commercial Vehicle": [34, 139, 34, 160],
        "Special Vehicle": [220, 20, 60, 160],
        "ê¸°íƒ€": [173, 216, 230, 160]
    }

    # --------------------------
    # ìƒë‹¨ í•„í„° ë°”
    # --------------------------
    col1, col2, col3, col4, col5, col6 = st.columns([1, 1, 1, 1, 1, 1])
    with col1:
        st.markdown("### Hyundai-Kia ERP")
    with col2:
        st.write("")
    with col3:
        st.write("")
    with col4:
        year = st.selectbox("ì—°ë„", sorted(df["ì—°ë„"].dropna().unique()), key="export_year")
    with col5:
        all_countries = sorted(df["ì§€ì—­ëª…"].dropna().unique())
        country_kor = st.selectbox("êµ­ê°€ (ì§€ì—­ëª…)", ["ì „ì²´"] + all_countries, key="export_country")
    with col6:
        all_vehicle_types = sorted(df["ì°¨ëŸ‰ êµ¬ë¶„"].dropna().unique())
        vehicle_type = st.selectbox("ì°¨ëŸ‰ êµ¬ë¶„", ["ì „ì²´"] + all_vehicle_types, key="export_vehicle")

    # --------------------------
    # í•„í„° ì ìš©
    # --------------------------
    df_filtered = df[df["ì—°ë„"] == year].copy()
    if country_kor != "ì „ì²´":
        df_filtered = df_filtered[df_filtered["ì§€ì—­ëª…"] == country_kor]
    if vehicle_type != "ì „ì²´":
        df_filtered = df_filtered[df_filtered["ì°¨ëŸ‰ êµ¬ë¶„"] == vehicle_type]

    df_filtered["ì´ìˆ˜ì¶œ"] = df_filtered[month_cols].sum(axis=1, numeric_only=True)

    # --------------------------
    # ìœ„ì¹˜ì •ë³´ ë³‘í•© (ì§€ì—­ëª… ê¸°ì¤€)
    # --------------------------
    loc_df = load_csv("data/ì„¸ì¼ì¦ˆíŒŒì¼/ì§€ì—­ë³„_ìœ„ì¹˜ì •ë³´.csv")
    if loc_df is None:
        st.stop()
    try:
        merged = pd.merge(df_filtered, loc_df, on="ì§€ì—­ëª…", how="left")
        merged = merged.dropna(subset=["ìœ„ë„", "ê²½ë„", "ì´ìˆ˜ì¶œ"])
    except Exception as e:
        st.error(f"ìœ„ì¹˜ ì •ë³´ ë³‘í•© ì¤‘ ì˜¤ë¥˜: {e}")
        st.stop()

    # =========================================================
    # ìƒë‹¨: ì§€ë„ + ìˆ˜ì¶œ ìš”ì•½ í‘œ
    # =========================================================
    colA, colB, colC = st.columns([4,3,2])
    
    with colA:
        st.subheader("ğŸ­ ê³µì¥ë³„ ì´ ìƒì‚°ëŸ‰ (ë¸Œëœë“œ í†µí•© ë¹„êµ)")

        def load_data():
            hyundai = pd.read_csv("data/processed/í˜„ëŒ€_í•´ì™¸ê³µì¥íŒë§¤ì‹¤ì _ì „ì²˜ë¦¬.CSV")
            kia = pd.read_csv("data/processed/ê¸°ì•„_í•´ì™¸ê³µì¥íŒë§¤ì‹¤ì _ì „ì²˜ë¦¬.CSV")

            # 'ì°¨ì¢…' ëˆ„ë½ ëŒ€ë¹„
            if "ì°¨ì¢…" not in hyundai.columns:
                hyundai["ì°¨ì¢…"] = "ê¸°íƒ€"
            if "ì°¨ì¢…" not in kia.columns:
                kia["ì°¨ì¢…"] = "ê¸°íƒ€"

            hyundai["ë¸Œëœë“œ"] = "í˜„ëŒ€"
            kia["ë¸Œëœë“œ"] = "ê¸°ì•„"
            return pd.concat([hyundai, kia], ignore_index=True)

        month_cols = [f"{i}ì›”" for i in range(1, 13)]
        prod_df = load_data()
        prod_df[month_cols] = prod_df[month_cols].apply(pd.to_numeric, errors="coerce")

        # (1) ì „ì²´ ê³µì¥ ëª©ë¡ (ë¸Œëœë“œ+ê³µì¥ëª…(êµ­ê°€)) ë§Œë“¤ê¸°
        factory_master = (
            prod_df[["ë¸Œëœë“œ", "ê³µì¥ëª…(êµ­ê°€)"]]
            .drop_duplicates()
            .reset_index(drop=True)
        )

        # (2) ì—°ë„ í•„í„° í›„ groupbyë¡œ ìƒì‚°ëŸ‰ ì§‘ê³„
        filtered = prod_df[prod_df["ì—°ë„"] == year].copy()
        grouped = filtered.groupby(["ë¸Œëœë“œ", "ê³µì¥ëª…(êµ­ê°€)"])[month_cols].sum(numeric_only=True)
        grouped["ì´ìƒì‚°"] = grouped.sum(axis=1)
        grouped = grouped.reset_index()

        # (3) ê³µì¥ ëª©ë¡ê³¼ left join â†’ ì—†ëŠ” ê³µì¥ì€ 0ìœ¼ë¡œ ì±„ì›€
        merged = pd.merge(factory_master, grouped, on=["ë¸Œëœë“œ", "ê³µì¥ëª…(êµ­ê°€)"], how="left")
        merged["ì´ìƒì‚°"] = merged["ì´ìƒì‚°"].fillna(0)  # NaN â†’ 0
        # (ì›”ë³„ ì»¬ëŸ¼ë„ 0ìœ¼ë¡œ ì±„ìš°ê³  ì‹¶ë‹¤ë©´ .fillna(0, inplace=True) ë“±ìœ¼ë¡œ ì²˜ë¦¬

        # ì´ì œ mergedì—ëŠ” "ì—°ë„ ë°ì´í„°ê°€ ì—†ì–´ë„" ê³µì¥ëª… ì „ì²´ê°€ ë“¤ì–´ìˆìŒ
        if merged["ì´ìƒì‚°"].sum() == 0:
            st.warning("ì„ íƒí•œ ì—°ë„ì— í•´ë‹¹í•˜ëŠ” ìƒì‚° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ 0).")
        else:
            import altair as alt
            chart = alt.Chart(merged).mark_bar().encode(
                x=alt.X("ì´ìƒì‚°:Q", title="ì´ ìƒì‚°ëŸ‰"),
                y=alt.Y("ê³µì¥ëª…(êµ­ê°€):N", sort="-x", title="ê³µì¥"),
                color="ë¸Œëœë“œ:N"
            ).properties(
                width=420,
                height=420,
                title="ê³µì¥ë³„ ì´ ìƒì‚°ëŸ‰ ë¹„êµ (í˜„ëŒ€ + ê¸°ì•„)"
            )
            st.altair_chart(chart, use_container_width=True)

    with colB:
        st.subheader("ğŸ—ºï¸ êµ­ê°€ë³„ ìˆ˜ì¶œ ì§€ë„")
        if len(merged) == 0:
            st.warning("í‘œì‹œí•  ì§€ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ë°”ê¿”ë³´ì„¸ìš”.")
        else:
            color = color_map.get(vehicle_type, [173, 216, 230, 160])
            st.pydeck_chart(pdk.Deck(
                map_style="mapbox://styles/mapbox/light-v9",
                initial_view_state=pdk.ViewState(latitude=20, longitude=0, zoom=1.3),
                layers=[
                    pdk.Layer(
                        "ScatterplotLayer",
                        data=merged,
                        get_position='[ê²½ë„, ìœ„ë„]',
                        get_radius='ì´ìˆ˜ì¶œ / 0.5',
                        get_fill_color=f"[{color[0]}, {color[1]}, {color[2]}, 160]",
                        pickable=True
                    )
                ],
                tooltip={"text": "{ì§€ì—­ëª…}\nì°¨ëŸ‰: {ì°¨ëŸ‰ êµ¬ë¶„}\nìˆ˜ì¶œëŸ‰: {ì´ìˆ˜ì¶œ} ëŒ€"}
            ))

    with colC:
        st.subheader("ğŸ“¦ êµ­ê°€ë³„ ìˆ˜ì¶œ ìš”ì•½")
        st.markdown("""
            <style>
            table {
                width: 100% !important;
                table-layout: fixed;
                border: 2px solid #000 !important;
                border-radius: 10px !important;
                border-collapse: separate;
                overflow: hidden;
            }
            </style>
            """, unsafe_allow_html=True)

        top_table = merged.sort_values("ì´ìˆ˜ì¶œ", ascending=False).head(3)
        bottom_table = merged.sort_values("ì´ìˆ˜ì¶œ").head(3)

        top_display = top_table[['ì§€ì—­ëª…', 'ì°¨ëŸ‰ êµ¬ë¶„', 'ì´ìˆ˜ì¶œ']].reset_index(drop=True)
        bottom_display = bottom_table[['ì§€ì—­ëª…', 'ì°¨ëŸ‰ êµ¬ë¶„', 'ì´ìˆ˜ì¶œ']].reset_index(drop=True)

        top_styled = (
            top_display.style
            .set_caption("ìƒìœ„ ìˆ˜ì¶œêµ­")
            .format({'ì´ìˆ˜ì¶œ': '{:,}'})
            .hide(axis="index")
        )
        bottom_styled = (
            bottom_display.style
            .set_caption("í•˜ìœ„ ìˆ˜ì¶œêµ­")
            .format({'ì´ìˆ˜ì¶œ': '{:,}'})
            .hide(axis="index")
        )

        st.markdown(top_styled.to_html(), unsafe_allow_html=True)
        st.markdown("<div style='margin-top:20px;'></div>", unsafe_allow_html=True)
        st.markdown(bottom_styled.to_html(), unsafe_allow_html=True)

    # =========================================================
    # í•˜ë‹¨: ë‰´ìŠ¤ ì„¹ì…˜
    # =========================================================
    colLeft, colRight = st.columns([1, 1])
    
    with colLeft:
        st.write("")
    
    with colRight:
        st.subheader("ìë™ì°¨ ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤")
        articles = fetch_naver_news(query="êµ­ë‚´ì°¨ëŸ‰ í•´ì™¸ ë°˜ì‘", display=3, sort="date")
        if not articles:
            st.write("ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for article in articles:
                title = remove_html_tags(article.get("title", ""))
                description = remove_html_tags(article.get("description", ""))
                link = article.get("link", "#")
                if len(description) > 70:
                    description = description[:70] + "..."
                st.markdown(f"**[{title}]({link})**")
                st.markdown(description)
                st.markdown("---")

    st.markdown("---")
